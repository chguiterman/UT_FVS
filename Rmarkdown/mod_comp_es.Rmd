---
title: "Growth models for Engelmann spruce"
author: "Courtney Giebink"
date: "October 1, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Model Selection

```{r include=FALSE}
library(tidyverse)
library(lme4)
library(lmerTest)
library(car)
library(broom.mixed)
```


```{r echo=FALSE}
load(file = '/home/giebink/Documents/Masters/UT/UT_FVS/data/formatted/glmm_es_z.Rdata')
```

The current large-diameter growth model for the UT variant of FVS is a multiple regression.

* SICOND: species site index on a 50-year age basis
* ASPECT: stand aspect
* SLOPE: stand slop
* DIA_C: tree diameter at breast height
* BAL: total basal area in trees larger than the subject tree
* CR_weib: tree's live crown ratio expressed as proportion
* PCCF: crown competition factor on the subplot level
* CCF: stand crown competition factor

All the covariates above are significant in the current model for Engelmann spruce, except SLOPE *^2*, DIA_C*^2*, and PCCF. In the model, the response variable (dds) and diameter at breast height (DIA_C) are log transformed to linearize the relationship. Basal area of larger trees than the subject tree (BAL) and CCF are divided by 100 to encourage model convergence. Below the structure for the current model is applied to annualized data set. A small number has to be added to `dds` because there is a missing ring (i.e. dds is zero) and the log of zero is impossible.

```{r}
#current growth model with tree ring data (annual)
#slope^2, dia^2, pccf insignificant in current lm
lm <- lm(log(dds+0.001)~
           #tree variables
           I(log(DIA_C))+I(DIA_C^2)+
           CR_weib+I(CR_weib^2)+
           #climate
           #competition/density
           I(BAL/100)+PCCF+I(CCF/100)+
           #site variables
           SICOND+SLOPE+I(SLOPE^2)+
           I(sin(ASPECT-0.7854)*SLOPE)+
           I(cos(ASPECT-0.7854)*SLOPE),
              data = glmm_es_z)
summary(lm)$coef
```

Since there is a lot of unaccounted for variability due to individual tree and year differences, the updated model will be a mixed effects model. A random intercept on Tree ID and Year will be added to account for different baselines. A random slope on DIA_C for each year will serve as a detrending method to reduce the age effect in growth.

Covariates are standardized, or mean-centered and divided by SD, to encourage model converage, which means there is no need for BAL and CCF to be divided by 100. In addition, the log transformation on DIA_C is problematic because a log of a negative number is impossible. Therefore, the log transformation on DIA_C will be removed.

A tree's growth response is also influenced by climate, or temperature and precipitation, during the growing season. By annualizing the model with tree rings, climate can be included as a covariate. `ppt_` is the total precipitation over the following monthly range. `tmin/max_` is the average temperature over the following monthly range. Climate variables were chosen based on model AIC score, as well as ability to project into the future (e.g. `wateryr`).

```{r warning=FALSE}
#add random effects
#random intercept for each tree
#random intercept for each year
#random slope on DBH for each tree (detrending method)
ran_slint <- lmer(log(dds+0.001)~
                    #tree variables
                    z.DIA_C+I(z.DIA_C^2)+ #remove log due to standardization
                    z.CR_weib+I(z.CR_weib^2)+
                    #climate
                    #competition/density
                    z.BAL+z.PCCF+z.CCF+ #remove /100 due to standardization
                    #site variables
                    z.SICOND+z.SLOPE+I(z.SLOPE^2)+
                    I(sin(z.ASPECT-0.7854)*z.SLOPE)+
                    I(cos(z.ASPECT-0.7854)*z.SLOPE)+
                    #random effects
                    (1+z.DIA_C|TRE_CN)+(1|Year),
                        data = glmm_es_z)
AIC(ran_slint)
#add climate
#wateryear the best AIC
#can also try 16mon pJun-Sep
#tmax pAug and pJulSep best
clim_wy <- lmer(log(tdds)~
                  #tree variables
                 z.DIA_C+I(z.DIA_C^2)+ #remove log due to standardization
                 z.CR_weib+I(z.CR_weib^2)+
                 #climate
                 z.wateryr+z.tmax_pAug+
                 #competition/density
                 z.BAL+z.PCCF+z.CCF+ #remove /100 due to standardization
                 #site variables
                 z.SICOND+z.SLOPE+I(z.SLOPE^2)+
                 z.sin+z.cos+
                 #random effects
                 (1+z.DIA_C|TRE_CN)+(1|Year),
               data = glmm_es_z)
AIC(clim_wy)
clim_1 <- lmer(log(tdds)~
                 #tree variables
                 z.DIA_C+I(z.DIA_C^2)+ #remove log due to standardization
                 z.CR_weib+I(z.CR_weib^2)+
                 #climate
                 z.ppt_pJunSep+z.tmax_pAug+ 
                 #competition/density
                 z.BAL+z.PCCF+z.CCF+ #remove /100 due to standardization
                 #site variables
                 z.SICOND+z.SLOPE+I(z.SLOPE^2)+
                 z.sin+z.cos
                 #random effects
                 (1+z.DIA_C|TRE_CN)+(1|Year),
               data = glmm_es_z)
AIC(clim_1)
```

Using the full model with all the possible covariates, I will test for collinearity between predictors with the `car` package.

```{r}
vif(clim_1)
```

A Variance Inflation Factor (VIF) above 3 shows strong collinearity. Therefore, `SLOPE` is collinear and should be removed.

```{r}
#reduce based on vif score
#slope
clim_1_red <- lmer(log(dds+0.001)~
                  #tree variables
                 z.DIA_C+I(z.DIA_C^2)+ #remove log due to standardization
                 z.CR_weib+I(z.CR_weib^2)+
                 #climate
                 z.ppt_JunAug+z.tmax_pAug+
                 #competition/density
                 z.BAL+z.PCCF+z.CCF+ #remove /100 due to standardization
                 #site variables
                 z.SICOND+I(z.SLOPE^2)+
                 I(sin(z.ASPECT-0.7854)*z.SLOPE)+
                 I(cos(z.ASPECT-0.7854)*z.SLOPE)+
                 #random effects
                 (1+z.DIA_C|TRE_CN)+(1|Year),
               data = glmm_es_z)
vif(clim_1_red)
```

```{r}
summary(clim_1_red)
```


```{r warning=FALSE}
#reduce based on significance
#PCCF
clim_1_red <- lmer(log(dds+0.001)~
                     #tree variables
                     z.DIA_C+I(z.DIA_C^2)+ #remove log due to standardization
                     z.CR_weib+I(z.CR_weib^2)+
                     #climate
                     z.ppt_JunAug+z.tmax_pAug+ #interaction not significant
                     #competition/density
                     z.BAL+z.CCF+ #remove /100 due to standardization
                     #site variables
                     z.SICOND+I(z.SLOPE^2)+
                     I(sin(z.ASPECT-0.7854)*z.SLOPE)+
                     I(cos(z.ASPECT-0.7854)*z.SLOPE)+
                     #random effects
                     (1+z.DIA_C|TRE_CN)+(1|Year),
                   data = glmm_es_z)
summary(clim_1_red)
```

Since transforming a variable to meet the assumptions of linearity and normality are not ideal, a generalized linear mixed model (GLMM) can be parameterized.

```{r warning=FALSE}
#gamma with log link
glmm_g <- glmer((dds+0.001)~
                  #tree variables
                  z.DIA_C+I(z.DIA_C^2)+
                  z.CR_weib+I(z.CR_weib^2)+
                  #climate
                  z.ppt_JunAug+z.tmax_pAug+
                  #competition/density
                  z.BAL+z.PCCF+z.CCF+ 
                  #site variables
                  z.SICOND+z.SLOPE+I(z.SLOPE^2)+
                  I(sin(z.ASPECT-0.7854)*z.SLOPE)+
                  I(cos(z.ASPECT-0.7854)*z.SLOPE)+
                  #random effects
                  (1+z.DIA_C|TRE_CN)+(1|Year),
                data = glmm_es_z,
                family = Gamma(link = "log"),
                glmerControl(optimizer = "bobyqa", 
                             optCtrl = list(maxfun = 100000)))
vif(glmm_g)
```

```{r}
#reduce based on vif score
glmm_red <- glmer((dds+0.001)~
                  #tree variables
                  z.DIA_C+I(z.DIA_C^2)+
                  z.CR_weib+I(z.CR_weib^2)+
                  #climate
                  z.ppt_JunAug+z.tmax_pAug+
                  #competition/density
                  z.BAL+z.PCCF+z.CCF+ 
                  #site variables
                  z.SICOND+I(z.SLOPE^2)+
                  I(sin(z.ASPECT-0.7854)*z.SLOPE)+
                  I(cos(z.ASPECT-0.7854)*z.SLOPE)+
                  #random effects
                  (1+z.DIA_C|TRE_CN)+(1|Year),
                data = glmm_es_z,
                family = Gamma(link = "log"),
                glmerControl(optimizer = "bobyqa", 
                             optCtrl = list(maxfun = 100000)))
vif(glmm_red)
```

```{r}
summary(glmm_red)$coef
```

```{r}
#reduce based on significance
#PCCF
glmm_red <- glmer((dds+0.001)~
                  #tree variables
                  z.DIA_C+I(z.DIA_C^2)+
                  z.CR_weib+I(z.CR_weib^2)+
                  #climate
                  z.ppt_JunAug+z.tmax_pAug+
                  #competition/density
                  z.BAL+z.CCF+ 
                  #site variables
                  z.SICOND+I(z.SLOPE^2)+
                  I(sin(z.ASPECT-0.7854)*z.SLOPE)+
                  I(cos(z.ASPECT-0.7854)*z.SLOPE)+
                  #random effects
                  (1+z.DIA_C|TRE_CN)+(1|Year),
                data = glmm_es_z,
                family = Gamma(link = "log"),
                glmerControl(optimizer = "bobyqa", 
                             optCtrl = list(maxfun = 100000)))
summary(glmm_red)$coef
```


```{r echo=FALSE,warning=FALSE}
models <- list(ran_slint = ran_slint, clim_1 = clim_1, clim_2 = clim_2, clim_3 = clim_3, clim_1_red = clim_1_red, glmm_g = glmm_g, glmm_red = glmm_red)
sum_mod <- purrr::map_df(models, broom::tidy, .id = "model") %>%
  dplyr::select(model,effect,term,estimate,p.value) %>%
  mutate_at(4, round, 6)
diag_mod <- purrr::map_df(models, broom::glance, .id = "model") %>%
  dplyr::select(model,AIC)
```

The table below easily compares the coefficients of the above models. The rows are coefficients and the columns are the different models. If a cell is NA, it means that the model doesn't include the coefficient of that row. Bolded coefficients are significant (i.e. p-value < 0.05), and non-bolded coefficients are insignificant. 

```{r echo=FALSE,warning=FALSE,message=FALSE}
#kable
library(kableExtra)
color.me <- sum_mod$estimate[sum_mod$p.value >=0.05]
    
sum_mod %>%
  rownames_to_column('cars') %>% # used to store row names (mutate deletes them)
  mutate(
    estimate = cell_spec(estimate, color = ifelse(estimate %in% color.me, "gray", "black"),
                         bold = ifelse(estimate %in% color.me, F, T))) %>%
  column_to_rownames('cars') %>% # used to put row names back in place
  filter(!is.na(p.value)) %>%
  dplyr::select(model,term,estimate) %>%
  spread(model,estimate,fill = NA) %>%
  kable(format = "html", digits = 6, escape = F) %>%
  kable_styling()
```

The Akaike's Information Criterion can be used to compare models, except between linear mixed models and generalized linear mixed models. A residual analysis will determine which model is best.

```{r echo=FALSE}
kable(diag_mod)
```
